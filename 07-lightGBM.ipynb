{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicación de la notebook 7\n",
    "\n",
    "En esta notebook se utiliza el modelo de LIGHT GBM, un modelo basado en arboles de decisión. Primero se hizo una corrida con los parametros default del regresor excepto por algunos ingresados manualmente, que son n_estimators = 4000 learning_rate=0.05 y min_child_samples=5. Con estos parametros, se consiguio un score de 0.11412. Luego, se hizo un tunning de distintos hyperparametros, hasta llegar al mejor score, de 0.10715, que resulto también el mejor score de clasificación de todo el trabajo práctico. \n",
    "\n",
    "Para conseguir este score, se utilizaron los siguientes parametros:\n",
    "\n",
    "params = {\"objective\" : \"rmse\",\n",
    "          \"boosting\" : \"gbdt\", \n",
    "          \"metric\" : \"rmse\",\n",
    "          \"num_iterations\" : 15148,\n",
    "          \"top_k\" : 30, \n",
    "          \"max_depth\" : max_depth, \n",
    "          \"num_leaves\" : num_leaves, \n",
    "          \"min_data_in_leaf\" : min_data_in_leaf, \n",
    "          \"learning_rate\" : 0.02,\n",
    "          \"bagging_fraction\" : 0.7, \n",
    "          \"bagging_seed\" : 3,\n",
    "          \"bagging_freq\" : 5, \n",
    "          \"feature_fraction\" : 0.5, \n",
    "          \"num_threads\" : 4\n",
    "         }\n",
    "         \n",
    "dataset_params = {\"max_bin\" : 200, \n",
    "                  \"min_data_in_bin\" : 3} \n",
    "\n",
    "Cabe destacar que se probó utilizar , con los parametros defalult (n_estimators = 4000 learning_rate=0.05 y min_child_samples=5), y se consiguio un resultado casi igual,al de sin embedding y parametros default, con score de 0.11555.\n",
    "\n",
    "### SUBMISSIONS CON ESTOS SCORES: \n",
    "\n",
    "- Parametros default sin embedding: submisionn_True-5-4000-0.05.csv (score = 0.11412)\n",
    "\n",
    "- Parametros default con embedding: submision_LGBM_embedd_True-5-4000-0.05-8-800-csv (Score = 0.11555)\n",
    "\n",
    "- Parametros cambiados sin embedding: submision_LGBM_muchos_param_True-5-4000-0.02-8-800-.csv (score = 0.10715) EL MEJOR\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=1-NYPQw5THU&feature=youtu.be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from pandas_summary import DataFrameSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('train_normalized_data.fth')\n",
    "df_test = pd.read_feather('test_normalized_data.fth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen', 'Promo2Weeks', \n",
    "            'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear', 'State', \n",
    "            'Week', 'Events', 'Promo_fw', 'Promo_bw', 'SchoolHoliday_fw', 'SchoolHoliday_bw', 'StateHoliday_bool_fw', 'StateHoliday_bool_bw']\n",
    "\n",
    "# cat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'State'] 'StateHoliday_bool_fw', 'StateHoliday_bool_bw'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen', 'Promo2Weeks', \n",
    "#            'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear', 'State', \n",
    "#            'Week', 'Events', 'Promo_fw', 'Promo_bw', 'SchoolHoliday_fw', 'SchoolHoliday_bw', 'Promo', 'SchoolHoliday',\n",
    "#            'StateHoliday_bool_fw', 'StateHoliday_bool_bw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contin_vars = ['CompetitionDistance', \n",
    "#              'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC', \n",
    "#               'Precipitationmm', 'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', \n",
    "#               'Max_Wind_SpeedKm_h', 'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', \n",
    "#               'trend_DE', 'AfterStateHoliday_bool', 'BeforeStateHoliday_bool']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "contin_vars = ['CompetitionDistance', \n",
    "   'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC',\n",
    "   'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', 'Max_Wind_SpeedKm_h', \n",
    "   'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', 'trend_DE', 'Promo', 'SchoolHoliday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contin_vars = ['CompetitionDistance', \n",
    "#   'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC',\n",
    "#   'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', 'Max_Wind_SpeedKm_h', \n",
    "#   'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', 'trend_DE',\n",
    "#    'Promo', 'SchoolHoliday']\n",
    "# contin_vars = [] 'AfterStateHoliday_bool', 'BeforeStateHoliday_bool'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_out_columns = ['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad en val: 30188, porcentaje: 0.9642465458145908\n"
     ]
    }
   ],
   "source": [
    "df_train = df[df.Date < datetime.datetime(2015, 7, 1)]  \n",
    "df_val = df[df.Date >= datetime.datetime(2015, 7, 1)]\n",
    "print(f'Cantidad en val: {len(df_val)}, porcentaje: {len(df_train)/(len(df_train) + len(df_val))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[cat_vars + contin_vars]\n",
    "X_val = df_val[cat_vars + contin_vars]\n",
    "X_test = df_test[cat_vars + contin_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((814150, 36), (30188, 36))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:84: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
      "  return reduction(axis=axis, out=out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "log_output = True\n",
    "    \n",
    "if log_output:\n",
    "    # Escala logaritmica\n",
    "    max_log_y = np.max(np.log(df[y_out_columns])).values\n",
    "    y_train = np.log(df_train[y_out_columns].values)/max_log_y\n",
    "    y_val = np.log(df_val[y_out_columns].values)/max_log_y\n",
    "else:\n",
    "    # Normalización\n",
    "    y_mean = df_train[y_out_columns].mean().values\n",
    "    y_std = df_train[y_out_columns].std().values\n",
    "    y_train = (df_train[y_out_columns].values - y_mean)/y_std\n",
    "    y_val = (df_val[y_out_columns].values - y_mean)/y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [X_train, X_val]\n",
    "X = pd.concat(frames)\n",
    "\n",
    "y = np.concatenate((y_train, y_val), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstudy = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Classifier\")\\nfunc = lambda trial: objective(trial, X, y)\\nstudy.optimize(func, n_trials=20)\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Classifier\")\n",
    "func = lambda trial: objective(trial, X, y)\n",
    "study.optimize(func, n_trials=20)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncat_var_dict = {'Store': 50, 'DayOfWeek': 2, 'Year': 2, 'Month': 2,\\n'Day': 10, 'StateHoliday': 2, 'CompetitionMonthsOpen': 2,\\n'Promo2Weeks': 1, 'StoreType': 2, 'Assortment': 3, 'PromoInterval': 3,\\n'CompetitionOpenSinceYear': 4, 'Promo2SinceYear': 4, 'State': 6,\\n'Week': 25, 'Events': 4, 'Promo_fw': 1,\\n'Promo_bw': 1, 'StateHoliday_bool_fw': 1,\\n'StateHoliday_bool_bw': 1, 'SchoolHoliday_fw': 1,\\n'SchoolHoliday_bw': 1,\\n'Promo': 2, 'SchoolHoliday': 2,\\n}\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "cat_var_dict = {'Store': 50, 'DayOfWeek': 2, 'Year': 2, 'Month': 2,\n",
    "'Day': 10, 'StateHoliday': 2, 'CompetitionMonthsOpen': 2,\n",
    "'Promo2Weeks': 1, 'StoreType': 2, 'Assortment': 3, 'PromoInterval': 3,\n",
    "'CompetitionOpenSinceYear': 4, 'Promo2SinceYear': 4, 'State': 6,\n",
    "'Week': 25, 'Events': 4, 'Promo_fw': 1,\n",
    "'Promo_bw': 1, 'StateHoliday_bool_fw': 1,\n",
    "'StateHoliday_bool_bw': 1, 'SchoolHoliday_fw': 1,\n",
    "'SchoolHoliday_bw': 1,\n",
    "'Promo': 2, 'SchoolHoliday': 2,\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.layers import Embedding, Input, Flatten, Concatenate, Dense, BatchNormalization, Activation, LeakyReLU, Dropout\n",
    "#from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def get_cat_vars_model(cat_vars, uniques, cat_var_dict):\\n    cat_vars_embed_outs = []\\n    cat_var_inputs = []\\n    for cat_var in cat_vars:\\n        cat_var_in = Input(shape=(1,), name=f\"{cat_var}_input\")\\n        cat_var_inputs.append(cat_var_in)\\n        embed_out = Embedding(uniques[cat_var][0], cat_var_dict[cat_var], name=f\\'{cat_var}_Embed\\')(cat_var_in)\\n        flatten_out = Flatten(name=f\"{cat_var}_flat\")(embed_out)\\n        cat_vars_embed_outs.append(flatten_out)\\n    return cat_var_inputs, cat_vars_embed_outs\\n\\ndef get_cont_vars_input(contin_vars, dense_layer=False):\\n    cont_vars_inputs = []\\n    cont_vars_outputs = []\\n    for cont_var in contin_vars:\\n        cont_var_in = Input(shape=(1,), name=f\"{cont_var}_input\")\\n        cont_vars_inputs.append(cont_var_in)\\n        if dense_layer:\\n            cont_var_out = Dense(1, name=f\"{cont_var}_input\", activation = \\'linear\\')(cont_var_in)\\n            cont_vars_outputs.append(cont_var_out)\\n        else:\\n            cont_vars_outputs.append(cont_var_in)\\n    return cont_vars_inputs, cont_vars_outputs\\n    '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def get_cat_vars_model(cat_vars, uniques, cat_var_dict):\n",
    "    cat_vars_embed_outs = []\n",
    "    cat_var_inputs = []\n",
    "    for cat_var in cat_vars:\n",
    "        cat_var_in = Input(shape=(1,), name=f\"{cat_var}_input\")\n",
    "        cat_var_inputs.append(cat_var_in)\n",
    "        embed_out = Embedding(uniques[cat_var][0], cat_var_dict[cat_var], name=f'{cat_var}_Embed')(cat_var_in)\n",
    "        flatten_out = Flatten(name=f\"{cat_var}_flat\")(embed_out)\n",
    "        cat_vars_embed_outs.append(flatten_out)\n",
    "    return cat_var_inputs, cat_vars_embed_outs\n",
    "\n",
    "def get_cont_vars_input(contin_vars, dense_layer=False):\n",
    "    cont_vars_inputs = []\n",
    "    cont_vars_outputs = []\n",
    "    for cont_var in contin_vars:\n",
    "        cont_var_in = Input(shape=(1,), name=f\"{cont_var}_input\")\n",
    "        cont_vars_inputs.append(cont_var_in)\n",
    "        if dense_layer:\n",
    "            cont_var_out = Dense(1, name=f\"{cont_var}_input\", activation = 'linear')(cont_var_in)\n",
    "            cont_vars_outputs.append(cont_var_out)\n",
    "        else:\n",
    "            cont_vars_outputs.append(cont_var_in)\n",
    "    return cont_vars_inputs, cont_vars_outputs\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uniques = DataFrameSummary(df[cat_vars]).summary().loc[['uniques']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_var_inputs, cat_vars_embed_outs = get_cat_vars_model(cat_vars, uniques, cat_var_dict)\n",
    "#cont_vars_inputs,  cont_vars_outs= get_cont_vars_input(contin_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASIFICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_child_samples=5\n",
    "min_data_in_leaf = 20\n",
    "n_estimators = 4000\n",
    "learning_rate=0.02\n",
    "max_depth = 8\n",
    "num_leaves = 800\n",
    "\n",
    "params = {\"objective\" : \"rmse\",\n",
    "          \"boosting\" : \"gbdt\", \n",
    "          \"metric\" : \"rmse\",\n",
    "          \"num_iterations\" : 15148,\n",
    "          \"top_k\" : 30, \n",
    "          \"max_depth\" : max_depth, \n",
    "          \"num_leaves\" : num_leaves, \n",
    "          \"min_data_in_leaf\" : min_data_in_leaf, \n",
    "          \"learning_rate\" : 0.02,\n",
    "          \"bagging_fraction\" : 0.7, \n",
    "          \"bagging_seed\" : 3,\n",
    "          \"bagging_freq\" : 5, \n",
    "          \"feature_fraction\" : 0.5, \n",
    "          \"num_threads\" : 4\n",
    "         }\n",
    "dataset_params = {\"max_bin\" : 200, \n",
    "                  \"min_data_in_bin\" : 3} \n",
    "\n",
    "\n",
    "\n",
    "model = LGBMRegressor(**params)\n",
    "#model = LGBMRegressor(min_child_samples=min_child_samples, n_estimators=n_estimators, learning_rate=learning_rate ,max_depth = max_depth, num_leaves = num_leaves, min_data_in_leaf = min_data_in_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params={\"early_stopping_rounds\":150, \n",
    "            \"eval_metric\" : 'RMSE', \n",
    "            \"eval_set\" : [(X_val, y_val.reshape(-1))],\n",
    "            'eval_names': ['valid'],\n",
    "            'verbose': 100,\n",
    "            'feature_name': 'auto', # that's actually the default\n",
    "            'categorical_feature': cat_vars\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] boosting is set=gbdt, boosting_type=gbdt will be ignored. Current value: boosting=gbdt\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] num_threads is set=4, n_jobs=-1 will be ignored. Current value: num_threads=4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "C:\\Users\\pedro\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\lightgbm\\basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid's rmse: 0.0218855\n",
      "[200]\tvalid's rmse: 0.0172241\n",
      "[300]\tvalid's rmse: 0.0152695\n",
      "[400]\tvalid's rmse: 0.0141639\n",
      "[500]\tvalid's rmse: 0.0134994\n",
      "[600]\tvalid's rmse: 0.0130321\n",
      "[700]\tvalid's rmse: 0.012729\n",
      "[800]\tvalid's rmse: 0.0124639\n",
      "[900]\tvalid's rmse: 0.0122713\n",
      "[1000]\tvalid's rmse: 0.0120771\n",
      "[1100]\tvalid's rmse: 0.0119376\n",
      "[1200]\tvalid's rmse: 0.0117478\n",
      "[1300]\tvalid's rmse: 0.0116084\n",
      "[1400]\tvalid's rmse: 0.0114823\n",
      "[1500]\tvalid's rmse: 0.0113914\n",
      "[1600]\tvalid's rmse: 0.0112964\n",
      "[1700]\tvalid's rmse: 0.011198\n",
      "[1800]\tvalid's rmse: 0.011125\n",
      "[1900]\tvalid's rmse: 0.0110718\n",
      "[2000]\tvalid's rmse: 0.0110126\n",
      "[2100]\tvalid's rmse: 0.0109624\n",
      "[2200]\tvalid's rmse: 0.0109215\n",
      "[2300]\tvalid's rmse: 0.0108909\n",
      "[2400]\tvalid's rmse: 0.0108454\n",
      "[2500]\tvalid's rmse: 0.0108162\n",
      "[2600]\tvalid's rmse: 0.0107903\n",
      "[2700]\tvalid's rmse: 0.0107653\n",
      "[2800]\tvalid's rmse: 0.0107434\n",
      "[2900]\tvalid's rmse: 0.0107226\n",
      "[3000]\tvalid's rmse: 0.0107087\n",
      "[3100]\tvalid's rmse: 0.0106903\n",
      "[3200]\tvalid's rmse: 0.0106708\n",
      "[3300]\tvalid's rmse: 0.0106537\n",
      "[3400]\tvalid's rmse: 0.0106417\n",
      "[3500]\tvalid's rmse: 0.0106239\n",
      "[3600]\tvalid's rmse: 0.0106048\n",
      "[3700]\tvalid's rmse: 0.0105901\n",
      "[3800]\tvalid's rmse: 0.0105814\n",
      "[3900]\tvalid's rmse: 0.0105656\n",
      "[4000]\tvalid's rmse: 0.0105562\n",
      "[4100]\tvalid's rmse: 0.0105418\n",
      "[4200]\tvalid's rmse: 0.0105321\n",
      "[4300]\tvalid's rmse: 0.010518\n",
      "[4400]\tvalid's rmse: 0.010508\n",
      "[4500]\tvalid's rmse: 0.0104968\n",
      "[4600]\tvalid's rmse: 0.0104913\n",
      "[4700]\tvalid's rmse: 0.0104799\n",
      "[4800]\tvalid's rmse: 0.0104721\n",
      "[4900]\tvalid's rmse: 0.010465\n",
      "[5000]\tvalid's rmse: 0.0104547\n",
      "[5100]\tvalid's rmse: 0.0104456\n",
      "[5200]\tvalid's rmse: 0.0104397\n",
      "[5300]\tvalid's rmse: 0.0104366\n",
      "[5400]\tvalid's rmse: 0.0104315\n",
      "[5500]\tvalid's rmse: 0.0104284\n",
      "[5600]\tvalid's rmse: 0.0104227\n",
      "[5700]\tvalid's rmse: 0.01042\n",
      "[5800]\tvalid's rmse: 0.0104148\n",
      "[5900]\tvalid's rmse: 0.0104108\n",
      "[6000]\tvalid's rmse: 0.0104076\n",
      "[6100]\tvalid's rmse: 0.0104009\n",
      "[6200]\tvalid's rmse: 0.0103951\n",
      "[6300]\tvalid's rmse: 0.0103917\n",
      "[6400]\tvalid's rmse: 0.0103881\n",
      "[6500]\tvalid's rmse: 0.0103825\n",
      "[6600]\tvalid's rmse: 0.0103794\n",
      "[6700]\tvalid's rmse: 0.010373\n",
      "[6800]\tvalid's rmse: 0.0103719\n",
      "[6900]\tvalid's rmse: 0.0103684\n",
      "[7000]\tvalid's rmse: 0.0103653\n",
      "[7100]\tvalid's rmse: 0.0103658\n",
      "[7200]\tvalid's rmse: 0.0103615\n",
      "[7300]\tvalid's rmse: 0.0103581\n",
      "[7400]\tvalid's rmse: 0.0103526\n",
      "[7500]\tvalid's rmse: 0.010349\n",
      "[7600]\tvalid's rmse: 0.0103459\n",
      "[7700]\tvalid's rmse: 0.0103442\n",
      "[7800]\tvalid's rmse: 0.0103432\n",
      "[7900]\tvalid's rmse: 0.0103408\n",
      "[8000]\tvalid's rmse: 0.0103373\n",
      "[8100]\tvalid's rmse: 0.0103377\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(bagging_fraction=0.7, bagging_freq=5, bagging_seed=3,\n",
       "              boosting=&#x27;gbdt&#x27;, feature_fraction=0.5, learning_rate=0.02,\n",
       "              max_depth=8, metric=&#x27;rmse&#x27;, min_data_in_leaf=20,\n",
       "              num_iterations=15148, num_leaves=800, num_threads=4,\n",
       "              objective=&#x27;rmse&#x27;, top_k=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(bagging_fraction=0.7, bagging_freq=5, bagging_seed=3,\n",
       "              boosting=&#x27;gbdt&#x27;, feature_fraction=0.5, learning_rate=0.02,\n",
       "              max_depth=8, metric=&#x27;rmse&#x27;, min_data_in_leaf=20,\n",
       "              num_iterations=15148, num_leaves=800, num_threads=4,\n",
       "              objective=&#x27;rmse&#x27;, top_k=30)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.7, bagging_freq=5, bagging_seed=3,\n",
       "              boosting='gbdt', feature_fraction=0.5, learning_rate=0.02,\n",
       "              max_depth=8, metric='rmse', min_data_in_leaf=20,\n",
       "              num_iterations=15148, num_leaves=800, num_threads=4,\n",
       "              objective='rmse', top_k=30)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.reshape(-1), **fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métrica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textrm{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\left(\\frac{\\hat{y}_i - y_i}{y_i}\\right)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9251516470349543"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if log_output:\n",
    "    y_pred_train = np.exp(model.predict(X_train, verbose=1)*max_log_y)\n",
    "    y_pred = np.exp(model.predict(X_val, verbose=1)*max_log_y)\n",
    "    y_pred_test = np.exp(model.predict(X_test, verbose=1)*max_log_y)\n",
    "else:\n",
    "    y_pred_train = model.predict(X_train, verbose=1)*y_std + y_mean\n",
    "    y_pred = model.predict(X_val, verbose=1)*y_std + y_mean\n",
    "    y_pred_test = model.predict(X_test, verbose=1)*y_std + y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06892762689029042"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "np.sqrt((((df_train['Sales'].values - y_pred_train)/df_train['Sales'].values)**2).sum()/len(y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.0787547817613104\n",
    "#0.07360962647765361"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11376692686385394"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validación\n",
    "np.sqrt((((df_val['Sales'].values - y_pred)/df_val['Sales'].values)**2).sum()/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.12355046837823216\n",
    "#0.11745998404616953"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sample_csv = pd.read_csv('rossmann/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_mean = {}\n",
    "for store, g_df in df.groupby('Store'):\n",
    "    stores_mean[store] = g_df[g_df['Sales'] > 0]['Sales'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Sales'] = df_test['Store'].apply(stores_mean.get)\n",
    "df_test.loc[df_test['Open'] == 0, 'Sales'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4759.096031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6942.568678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>8817.050891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>5539.358418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>6562.337612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>5568.420918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>8030.977041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>7589.598214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>5034.747182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>5508.567394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store        Sales\n",
       "0      0  4759.096031\n",
       "1      2  6942.568678\n",
       "2      6  8817.050891\n",
       "3      7  5539.358418\n",
       "4      8  6562.337612\n",
       "5      9  5568.420918\n",
       "6     10  8030.977041\n",
       "7     11  7589.598214\n",
       "8     12  5034.747182\n",
       "9     13  5508.567394"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['Store', 'Sales']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>702</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>878</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>1096</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>702</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1532</th>\n",
       "      <td>878</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Store  Sales\n",
       "543     702    0.0\n",
       "676     878    0.0\n",
       "840    1096    0.0\n",
       "1399    702    0.0\n",
       "1532    878    0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['Open'] == 0][['Store', 'Sales']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_csv['Sales'] = df_test['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_csv.to_csv(f'submision_baseline.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4759.096031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6942.568678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8817.050891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5539.358418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6562.337612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id        Sales\n",
       "0   1  4759.096031\n",
       "1   2  6942.568678\n",
       "2   3  8817.050891\n",
       "3   4  5539.358418\n",
       "4   5  6562.337612"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sumbit a la competición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_csv = pd.read_csv('rossmann/sample_submission.csv')\n",
    "sample_csv['Sales'] = y_pred_test\n",
    "sample_csv.head()\n",
    "\n",
    "sample_csv.to_csv(f'submision_LGBM_muchos_param_{log_output}-{min_child_samples}-{n_estimators}-{learning_rate}-{max_depth}-{num_leaves}-.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "326e4f63ad54c217260fc7be1c53acea6ef3ea6cd7ac93b3b02195c6d8fa7cb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
